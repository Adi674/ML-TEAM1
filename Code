import cv2
import numpy as np
import torch
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import time
import seaborn as sns
import pandas as pd
from torchvision import models
from IPython.display import clear_output
from sklearn.metrics import confusion_matrix
from google.colab.patches import cv2_imshow
from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive')

# Device setup
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Define CSRNet Model
class CSRNet(torch.nn.Module):
    def __init__(self):
        super(CSRNet, self).__init__()
        self.frontend = models.vgg16_bn(weights=models.VGG16_BN_Weights.DEFAULT).features[:30]  # Extract first 30 layers
        self.density_map = torch.nn.Conv2d(512, 1, kernel_size=1)  # 1-channel density map

    def forward(self, x):
        x = self.frontend(x)
        x = self.density_map(x)
        return x

# Instantiate Model
model = CSRNet().to(device)
model.eval()  # Set model to evaluation mode

# Preprocessing Function
def preprocess_frame(frame):
    transform = transforms.Compose([
        transforms.ToPILImage(),
        transforms.Resize((224, 224)),  # Resize for model compatibility
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    return transform(frame).unsqueeze(0)

# Load video
video_path = "/content/drive/MyDrive/vecteezy_a-crowd-walking-on-the-street-in-slow-motion_13996591.mp4"
cap = cv2.VideoCapture(video_path)

if not cap.isOpened():
    print(f"Error: Could not open video file at {video_path}")
    exit()

# Get video properties
original_fps = cap.get(cv2.CAP_PROP_FPS)
frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

new_fps = max(1, original_fps // 10)  # Reduce FPS to 1/10th, but ensure it's at least 1 FPS
frame_skip = max(1, int(original_fps / new_fps))  # Process every 10th frame

# Initialize Video Writer
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
output_video_path = "/content/drive/MyDrive/crowd_heatmap_output.mp4"
out = cv2.VideoWriter(output_video_path, fourcc, new_fps, (frame_width, frame_height))

frame_count = 0
crowd_counts = []
actual_counts = []  # Placeholder for actual values (for confusion matrix)
density_sum = None  # To accumulate density maps
frame_counter = 0   # Count frames processed

while cap.isOpened():
    ret, frame = cap.read()

    if not ret:
        break  # Exit if video ends or frame is unreadable

    frame_count += 1

    # Process only 1 out of every `frame_skip` frames
    if frame_count % frame_skip != 0:
        continue  

    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert to RGB
    input_tensor = preprocess_frame(frame_rgb).to(device)

    with torch.no_grad():
        density_map = model(input_tensor)
        crowd_count = density_map.sum().item()

    crowd_counts.append(crowd_count)  # Store count for graph
    frame_counter += 1

    print(f"Frame {frame_count} - Estimated Crowd Count: {crowd_count:.2f}")

    # Convert density map to NumPy and resize
    density_map_np = density_map.squeeze().cpu().numpy()
    density_map_resized = cv2.resize(density_map_np, (frame_width, frame_height), interpolation=cv2.INTER_CUBIC)

    # Accumulate density maps for final image
    if density_sum is None:
        density_sum = density_map_resized
    else:
        density_sum += density_map_resized

    # Normalize and apply heatmap for video
    density_map_norm = cv2.normalize(density_map_resized, None, 0, 255, cv2.NORM_MINMAX)
    density_map_uint8 = density_map_norm.astype(np.uint8)
    heatmap = cv2.applyColorMap(density_map_uint8, cv2.COLORMAP_JET)

    # Overlay heatmap on original frame
    overlay = cv2.addWeighted(frame.astype(np.uint8), 0.6, heatmap, 0.4, 0)

    out.write(overlay)  # Save processed frame

    time.sleep(0.00001)  # Small delay for display
    clear_output(wait=True)  # Clear output for smooth display

# Compute final heatmap by averaging
final_density_map = density_sum / frame_counter  # Average density map over frames
final_density_norm = cv2.normalize(final_density_map, None, 0, 255, cv2.NORM_MINMAX)
final_density_uint8 = final_density_norm.astype(np.uint8)
final_heatmap = cv2.applyColorMap(final_density_uint8, cv2.COLORMAP_JET)

# Save final heatmap image
final_heatmap_path = "/content/drive/MyDrive/final_crowd_heatmap.jpg"
cv2.imwrite(final_heatmap_path, final_heatmap)
print(f"Final overall heatmap image saved at: {final_heatmap_path}")

# Release resources
cap.release()
out.release()
print(f"Processed video saved at: {output_video_path}")

# Generate Graph: Crowd Density Over Time
plt.figure(figsize=(10, 5))
plt.plot(range(1, len(crowd_counts) + 1), crowd_counts, marker='o', linestyle='-', color='b', label="Estimated Crowd")
plt.xlabel("Frame Number")
plt.ylabel("Crowd Count")
plt.title("Crowd Density Over Time")
plt.legend()
plt.grid(True)
graph_path = "/content/drive/MyDrive/crowd_density_graph.png"
plt.savefig(graph_path)
plt.show()
print(f"Graph saved at: {graph_path}")

# Confusion Matrix (Dummy Example)
# Replace actual_counts with real ground truth values if available
actual_counts = np.random.randint(low=min(crowd_counts), high=max(crowd_counts), size=len(crowd_counts))

# Convert counts into categories (e.g., Low, Medium, High)
threshold_low, threshold_high = np.percentile(actual_counts, [33, 66])

def categorize_count(count):
    if count <= threshold_low:
        return "Low"
    elif count <= threshold_high:
        return "Medium"
    return "High"

y_true = [categorize_count(x) for x in actual_counts]
y_pred = [categorize_count(x) for x in crowd_counts]

# Generate Confusion Matrix
conf_matrix = confusion_matrix(y_true, y_pred, labels=["Low", "Medium", "High"])

# Plot Confusion Matrix
plt.figure(figsize=(6, 5))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=["Low", "Medium", "High"], yticklabels=["Low", "Medium", "High"])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix for Crowd Estimation")
conf_matrix_path = "/content/drive/MyDrive/crowd_confusion_matrix.png"
plt.savefig(conf_matrix_path)
plt.show()
print(f"Confusion matrix saved at: {conf_matrix_path}")
