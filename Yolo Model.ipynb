{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Function to assign unique IDs to detected people (basic DeepSort code)\n",
        "def assign_unique_ids(detections):\n",
        "    tracked_objects = {}\n",
        "    for detection in detections:\n",
        "        obj_id = str(uuid.uuid4())\n",
        "        tracked_objects[obj_id] = detection\n",
        "    return tracked_objects\n",
        "\n",
        "# Load YOLOv8 heavy model\n",
        "!pip install ultralytics\n",
        "model = YOLO('yolov8x.pt')  # Load yolov8x or other heavy model\n",
        "\n",
        "# Video input and output paths\n",
        "video_path = '/content/production_id_4196258 (720p).mp4' #@param {type:\"string\"}\n",
        "output_path = '/content/output_tracked_v8.mp4'\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "if not cap.isOpened():\n",
        "    print(f\"Error opening video file: {video_path}\")\n",
        "    exit()\n",
        "\n",
        "# Get video properties\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "# Create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or 'XVID'\n",
        "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    results = model(frame)\n",
        "\n",
        "    detections = []\n",
        "    for r in results:\n",
        "        for box in r.boxes:\n",
        "            if int(box.cls[0]) == 0:  # Assuming 'person' class is 0\n",
        "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "                conf = box.conf[0].item()\n",
        "                detections.append((x1, y1, x2, y2, conf))\n",
        "\n",
        "    tracked_people = assign_unique_ids(detections)\n",
        "\n",
        "    for obj_id, (x1, y1, x2, y2, conf) in tracked_people.items():\n",
        "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "        cv2.putText(frame, obj_id, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "\n",
        "    cv2.putText(frame, f\"People Count: {len(tracked_people)}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "\n",
        "    out.write(frame)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "print(f\"Video with tracking saved to: {output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vf40bHT77bwG",
        "outputId": "e0a5b8b9-0ab1-49cf-d016-a134015324f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.81)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.20.1+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: nvidia-cufft-cu12\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed nvidia-cufft-cu12\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8x.pt to 'yolov8x.pt'...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 131M/131M [00:01<00:00, 119MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 24 persons, 1 car, 1 backpack, 1 handbag, 2993.6ms\n",
            "Speed: 3.5ms preprocess, 2993.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 car, 1 backpack, 2 handbags, 2277.9ms\n",
            "Speed: 2.9ms preprocess, 2277.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 handbag, 2272.4ms\n",
            "Speed: 3.8ms preprocess, 2272.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 car, 1 handbag, 2276.8ms\n",
            "Speed: 3.0ms preprocess, 2276.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 3202.4ms\n",
            "Speed: 3.4ms preprocess, 3202.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 2327.6ms\n",
            "Speed: 3.1ms preprocess, 2327.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 1 car, 1 handbag, 2273.5ms\n",
            "Speed: 3.0ms preprocess, 2273.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 handbag, 2303.4ms\n",
            "Speed: 3.0ms preprocess, 2303.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 handbag, 2259.9ms\n",
            "Speed: 3.0ms preprocess, 2259.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 car, 2 handbags, 3191.2ms\n",
            "Speed: 3.1ms preprocess, 3191.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 1 car, 2 handbags, 2319.7ms\n",
            "Speed: 2.9ms preprocess, 2319.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 2 handbags, 2304.3ms\n",
            "Speed: 2.8ms preprocess, 2304.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 27 persons, 2 handbags, 2320.8ms\n",
            "Speed: 2.3ms preprocess, 2320.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 2 handbags, 2272.9ms\n",
            "Speed: 2.8ms preprocess, 2272.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 2 handbags, 3263.0ms\n",
            "Speed: 2.9ms preprocess, 3263.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 1 car, 3 handbags, 2283.8ms\n",
            "Speed: 2.9ms preprocess, 2283.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 3 handbags, 2301.2ms\n",
            "Speed: 3.4ms preprocess, 2301.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 26 persons, 1 car, 2 handbags, 2469.9ms\n",
            "Speed: 3.2ms preprocess, 2469.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 car, 2 handbags, 2297.4ms\n",
            "Speed: 2.9ms preprocess, 2297.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 3 handbags, 3259.9ms\n",
            "Speed: 3.3ms preprocess, 3259.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 3 handbags, 2720.4ms\n",
            "Speed: 2.8ms preprocess, 2720.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 handbags, 2268.0ms\n",
            "Speed: 2.8ms preprocess, 2268.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 handbag, 2294.2ms\n",
            "Speed: 3.0ms preprocess, 2294.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 2 handbags, 2335.5ms\n",
            "Speed: 3.0ms preprocess, 2335.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 2 handbags, 3236.4ms\n",
            "Speed: 3.7ms preprocess, 3236.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 3 handbags, 2289.0ms\n",
            "Speed: 2.9ms preprocess, 2289.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 3 handbags, 2287.6ms\n",
            "Speed: 3.0ms preprocess, 2287.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 handbag, 2288.8ms\n",
            "Speed: 3.5ms preprocess, 2288.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 handbag, 2321.3ms\n",
            "Speed: 3.8ms preprocess, 2321.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 handbags, 3209.5ms\n",
            "Speed: 2.9ms preprocess, 3209.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2286.5ms\n",
            "Speed: 3.6ms preprocess, 2286.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2295.5ms\n",
            "Speed: 2.9ms preprocess, 2295.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 handbags, 2292.0ms\n",
            "Speed: 3.0ms preprocess, 2292.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 2 handbags, 2380.5ms\n",
            "Speed: 3.7ms preprocess, 2380.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 handbag, 3150.2ms\n",
            "Speed: 3.0ms preprocess, 3150.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 handbag, 2325.5ms\n",
            "Speed: 2.9ms preprocess, 2325.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 2 handbags, 2329.0ms\n",
            "Speed: 4.1ms preprocess, 2329.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 handbag, 2303.1ms\n",
            "Speed: 4.2ms preprocess, 2303.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2 handbags, 2513.5ms\n",
            "Speed: 2.9ms preprocess, 2513.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2 handbags, 3016.2ms\n",
            "Speed: 2.9ms preprocess, 3016.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 2 handbags, 2299.8ms\n",
            "Speed: 2.9ms preprocess, 2299.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 3 handbags, 2297.3ms\n",
            "Speed: 2.9ms preprocess, 2297.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 3 handbags, 2298.9ms\n",
            "Speed: 2.9ms preprocess, 2298.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 3 handbags, 2634.4ms\n",
            "Speed: 2.9ms preprocess, 2634.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 car, 2 handbags, 2946.3ms\n",
            "Speed: 2.9ms preprocess, 2946.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 car, 2 handbags, 2283.2ms\n",
            "Speed: 2.8ms preprocess, 2283.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 2 handbags, 2293.6ms\n",
            "Speed: 2.7ms preprocess, 2293.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 3 handbags, 2302.7ms\n",
            "Speed: 3.8ms preprocess, 2302.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 car, 3 handbags, 2730.2ms\n",
            "Speed: 2.9ms preprocess, 2730.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 car, 3 handbags, 2824.8ms\n",
            "Speed: 3.1ms preprocess, 2824.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 car, 3 handbags, 2299.6ms\n",
            "Speed: 2.9ms preprocess, 2299.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 3 handbags, 2304.4ms\n",
            "Speed: 3.4ms preprocess, 2304.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 handbag, 2296.0ms\n",
            "Speed: 3.0ms preprocess, 2296.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 handbag, 2772.0ms\n",
            "Speed: 2.9ms preprocess, 2772.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 handbag, 2756.2ms\n",
            "Speed: 3.0ms preprocess, 2756.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 handbags, 2282.5ms\n",
            "Speed: 2.9ms preprocess, 2282.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 3 handbags, 2303.1ms\n",
            "Speed: 2.9ms preprocess, 2303.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 handbag, 2313.2ms\n",
            "Speed: 3.1ms preprocess, 2313.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2 handbags, 2836.7ms\n",
            "Speed: 2.9ms preprocess, 2836.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 handbag, 2713.4ms\n",
            "Speed: 3.3ms preprocess, 2713.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 handbags, 2299.3ms\n",
            "Speed: 2.9ms preprocess, 2299.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 handbag, 2296.4ms\n",
            "Speed: 3.1ms preprocess, 2296.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2 handbags, 2278.8ms\n",
            "Speed: 2.9ms preprocess, 2278.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 3 handbags, 2897.9ms\n",
            "Speed: 2.9ms preprocess, 2897.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 2 handbags, 2644.7ms\n",
            "Speed: 3.5ms preprocess, 2644.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 handbag, 2282.8ms\n",
            "Speed: 2.9ms preprocess, 2282.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 2 handbags, 2312.5ms\n",
            "Speed: 2.9ms preprocess, 2312.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 handbags, 2277.0ms\n",
            "Speed: 2.9ms preprocess, 2277.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 3 handbags, 2996.5ms\n",
            "Speed: 3.0ms preprocess, 2996.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 handbags, 2513.2ms\n",
            "Speed: 2.8ms preprocess, 2513.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 3 handbags, 2294.0ms\n",
            "Speed: 2.9ms preprocess, 2294.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 4 handbags, 2305.8ms\n",
            "Speed: 2.9ms preprocess, 2305.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 4 handbags, 2278.4ms\n",
            "Speed: 2.8ms preprocess, 2278.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 handbags, 3052.2ms\n",
            "Speed: 3.0ms preprocess, 3052.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 handbags, 2445.6ms\n",
            "Speed: 4.5ms preprocess, 2445.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 handbags, 2287.1ms\n",
            "Speed: 2.8ms preprocess, 2287.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 handbags, 2278.9ms\n",
            "Speed: 3.0ms preprocess, 2278.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 handbags, 2302.4ms\n",
            "Speed: 2.9ms preprocess, 2302.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 3 handbags, 3136.7ms\n",
            "Speed: 7.4ms preprocess, 3136.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 handbags, 2371.6ms\n",
            "Speed: 3.1ms preprocess, 2371.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 3 handbags, 2289.2ms\n",
            "Speed: 3.0ms preprocess, 2289.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 2 handbags, 2299.0ms\n",
            "Speed: 2.9ms preprocess, 2299.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 handbags, 2288.2ms\n",
            "Speed: 2.8ms preprocess, 2288.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 car, 2 handbags, 6468.8ms\n",
            "Speed: 3.0ms preprocess, 6468.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 handbag, 2291.0ms\n",
            "Speed: 3.1ms preprocess, 2291.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 car, 1 umbrella, 1 handbag, 2275.8ms\n",
            "Speed: 5.0ms preprocess, 2275.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 car, 1 handbag, 2285.6ms\n",
            "Speed: 2.9ms preprocess, 2285.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 handbags, 2295.4ms\n",
            "Speed: 2.9ms preprocess, 2295.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 handbag, 3271.8ms\n",
            "Speed: 3.0ms preprocess, 3271.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 handbags, 2300.1ms\n",
            "Speed: 3.3ms preprocess, 2300.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 handbag, 2298.7ms\n",
            "Speed: 3.2ms preprocess, 2298.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2 handbags, 2299.7ms\n",
            "Speed: 2.8ms preprocess, 2299.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 handbags, 2303.9ms\n",
            "Speed: 3.0ms preprocess, 2303.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 handbag, 3221.1ms\n",
            "Speed: 2.9ms preprocess, 3221.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 handbags, 2310.8ms\n",
            "Speed: 2.9ms preprocess, 2310.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 handbag, 2286.6ms\n",
            "Speed: 2.9ms preprocess, 2286.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 handbag, 2302.1ms\n",
            "Speed: 2.9ms preprocess, 2302.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 handbag, 2318.2ms\n",
            "Speed: 3.0ms preprocess, 2318.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 handbag, 3185.1ms\n",
            "Speed: 2.9ms preprocess, 3185.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 handbag, 2282.3ms\n",
            "Speed: 3.5ms preprocess, 2282.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 handbags, 2321.6ms\n",
            "Speed: 3.0ms preprocess, 2321.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2 handbags, 2443.1ms\n",
            "Speed: 3.2ms preprocess, 2443.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 2 handbags, 5996.5ms\n",
            "Speed: 2.9ms preprocess, 5996.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 handbags, 2294.4ms\n",
            "Speed: 2.9ms preprocess, 2294.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 2 handbags, 2289.2ms\n",
            "Speed: 2.9ms preprocess, 2289.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2 handbags, 2319.4ms\n",
            "Speed: 2.9ms preprocess, 2319.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 2 handbags, 2387.1ms\n",
            "Speed: 2.8ms preprocess, 2387.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 handbags, 3129.5ms\n",
            "Speed: 3.0ms preprocess, 3129.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 handbags, 2290.1ms\n",
            "Speed: 2.9ms preprocess, 2290.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 handbags, 3501.0ms\n",
            "Speed: 2.5ms preprocess, 3501.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 2 handbags, 6743.8ms\n",
            "Speed: 4.1ms preprocess, 6743.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 handbags, 2840.4ms\n",
            "Speed: 3.1ms preprocess, 2840.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 2 handbags, 2303.8ms\n",
            "Speed: 3.0ms preprocess, 2303.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 handbags, 2284.2ms\n",
            "Speed: 2.9ms preprocess, 2284.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2 handbags, 2287.6ms\n",
            "Speed: 2.9ms preprocess, 2287.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 handbags, 3282.0ms\n",
            "Speed: 2.9ms preprocess, 3282.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2 handbags, 2287.8ms\n",
            "Speed: 2.9ms preprocess, 2287.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 3 handbags, 2290.2ms\n",
            "Speed: 2.9ms preprocess, 2290.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 2 handbags, 2298.6ms\n",
            "Speed: 3.1ms preprocess, 2298.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 2 handbags, 2304.6ms\n",
            "Speed: 3.1ms preprocess, 2304.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 1 car, 1 motorcycle, 3 handbags, 3227.1ms\n",
            "Speed: 2.9ms preprocess, 3227.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 2 handbags, 2280.8ms\n",
            "Speed: 2.9ms preprocess, 2280.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2 handbags, 2291.4ms\n",
            "Speed: 2.8ms preprocess, 2291.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 3 handbags, 2291.4ms\n",
            "Speed: 2.9ms preprocess, 2291.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2 handbags, 2348.1ms\n",
            "Speed: 3.0ms preprocess, 2348.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 3 handbags, 3184.6ms\n",
            "Speed: 2.9ms preprocess, 3184.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 3 handbags, 2329.4ms\n",
            "Speed: 2.8ms preprocess, 2329.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 3 handbags, 2277.1ms\n",
            "Speed: 3.0ms preprocess, 2277.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 4 handbags, 2284.8ms\n",
            "Speed: 2.9ms preprocess, 2284.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 3 handbags, 2419.9ms\n",
            "Speed: 2.6ms preprocess, 2419.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 3 handbags, 3092.9ms\n",
            "Speed: 2.9ms preprocess, 3092.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 3 handbags, 2288.6ms\n",
            "Speed: 2.5ms preprocess, 2288.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 3 handbags, 2298.8ms\n",
            "Speed: 2.9ms preprocess, 2298.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 car, 3 handbags, 2289.9ms\n",
            "Speed: 3.0ms preprocess, 2289.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 car, 3 handbags, 2479.4ms\n",
            "Speed: 2.9ms preprocess, 2479.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 3 handbags, 3047.5ms\n",
            "Speed: 2.9ms preprocess, 3047.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 handbags, 2280.6ms\n",
            "Speed: 3.0ms preprocess, 2280.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 3 handbags, 2293.8ms\n",
            "Speed: 3.1ms preprocess, 2293.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2 handbags, 2300.4ms\n",
            "Speed: 2.8ms preprocess, 2300.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 handbags, 2992.4ms\n",
            "Speed: 2.9ms preprocess, 2992.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 handbags, 1 toilet, 3624.8ms\n",
            "Speed: 2.9ms preprocess, 3624.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 1 car, 2 handbags, 2299.4ms\n",
            "Speed: 2.9ms preprocess, 2299.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 handbags, 2826.1ms\n",
            "Speed: 2.9ms preprocess, 2826.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 2 handbags, 2297.7ms\n",
            "Speed: 3.1ms preprocess, 2297.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 15 persons, 3 handbags, 3260.5ms\n",
            "Speed: 3.9ms preprocess, 3260.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 3 handbags, 2286.9ms\n",
            "Speed: 2.9ms preprocess, 2286.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 3 handbags, 2298.9ms\n",
            "Speed: 3.7ms preprocess, 2298.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 3 handbags, 2305.4ms\n",
            "Speed: 2.9ms preprocess, 2305.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 3 handbags, 2297.2ms\n",
            "Speed: 2.9ms preprocess, 2297.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 handbags, 3280.7ms\n",
            "Speed: 2.9ms preprocess, 3280.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 2 handbags, 2304.7ms\n",
            "Speed: 2.9ms preprocess, 2304.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 3 handbags, 2293.5ms\n",
            "Speed: 3.9ms preprocess, 2293.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 3 handbags, 2296.5ms\n",
            "Speed: 3.1ms preprocess, 2296.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 3 handbags, 2292.9ms\n",
            "Speed: 3.0ms preprocess, 2292.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 3 handbags, 3250.2ms\n",
            "Speed: 3.1ms preprocess, 3250.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 3 handbags, 2298.0ms\n",
            "Speed: 2.4ms preprocess, 2298.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 3 handbags, 2300.8ms\n",
            "Speed: 3.0ms preprocess, 2300.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 3 handbags, 2292.5ms\n",
            "Speed: 3.7ms preprocess, 2292.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 3 handbags, 2318.6ms\n",
            "Speed: 3.9ms preprocess, 2318.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 3 handbags, 3205.1ms\n",
            "Speed: 2.9ms preprocess, 3205.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 3 handbags, 2285.0ms\n",
            "Speed: 2.9ms preprocess, 2285.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 2 handbags, 2285.3ms\n",
            "Speed: 2.8ms preprocess, 2285.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 3 handbags, 2326.3ms\n",
            "Speed: 2.9ms preprocess, 2326.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 2 handbags, 2374.9ms\n",
            "Speed: 4.2ms preprocess, 2374.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 2 handbags, 3150.9ms\n",
            "Speed: 2.9ms preprocess, 3150.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 backpack, 2 handbags, 2304.2ms\n",
            "Speed: 3.8ms preprocess, 2304.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 handbag, 2322.7ms\n",
            "Speed: 3.0ms preprocess, 2322.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 3 handbags, 2313.3ms\n",
            "Speed: 2.8ms preprocess, 2313.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2 handbags, 2511.6ms\n",
            "Speed: 2.6ms preprocess, 2511.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 backpack, 3 handbags, 3020.1ms\n",
            "Speed: 3.2ms preprocess, 3020.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2 handbags, 2336.8ms\n",
            "Speed: 3.2ms preprocess, 2336.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2 handbags, 2312.0ms\n",
            "Speed: 2.9ms preprocess, 2312.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 3 handbags, 2305.5ms\n",
            "Speed: 3.0ms preprocess, 2305.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 4 handbags, 2657.9ms\n",
            "Speed: 3.6ms preprocess, 2657.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 3 handbags, 2951.2ms\n",
            "Speed: 2.9ms preprocess, 2951.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 3 handbags, 2300.8ms\n",
            "Speed: 2.9ms preprocess, 2300.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 4 handbags, 2288.2ms\n",
            "Speed: 2.9ms preprocess, 2288.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 4 handbags, 2297.4ms\n",
            "Speed: 2.9ms preprocess, 2297.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 3 handbags, 2710.8ms\n",
            "Speed: 2.9ms preprocess, 2710.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 3 handbags, 2889.4ms\n",
            "Speed: 2.5ms preprocess, 2889.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 5 handbags, 2304.1ms\n",
            "Speed: 2.9ms preprocess, 2304.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 3 handbags, 2296.0ms\n",
            "Speed: 2.8ms preprocess, 2296.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 3 handbags, 2307.8ms\n",
            "Speed: 3.1ms preprocess, 2307.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 3 handbags, 2826.6ms\n",
            "Speed: 3.2ms preprocess, 2826.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 3 handbags, 2742.5ms\n",
            "Speed: 3.2ms preprocess, 2742.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 3 handbags, 2303.3ms\n",
            "Speed: 3.1ms preprocess, 2303.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 3 handbags, 2308.7ms\n",
            "Speed: 2.9ms preprocess, 2308.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 3 handbags, 2291.9ms\n",
            "Speed: 2.9ms preprocess, 2291.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 3 handbags, 2905.6ms\n",
            "Speed: 3.0ms preprocess, 2905.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 3 handbags, 2651.7ms\n",
            "Speed: 3.0ms preprocess, 2651.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 4 handbags, 2304.5ms\n",
            "Speed: 3.0ms preprocess, 2304.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 4 handbags, 2311.0ms\n",
            "Speed: 3.7ms preprocess, 2311.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 3 handbags, 2299.2ms\n",
            "Speed: 2.9ms preprocess, 2299.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 4 handbags, 3010.0ms\n",
            "Speed: 4.3ms preprocess, 3010.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 3 handbags, 2559.1ms\n",
            "Speed: 3.4ms preprocess, 2559.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 3 handbags, 2297.9ms\n",
            "Speed: 2.9ms preprocess, 2297.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 2 handbags, 2294.2ms\n",
            "Speed: 3.0ms preprocess, 2294.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 1 car, 2 handbags, 2326.2ms\n",
            "Speed: 3.5ms preprocess, 2326.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 handbags, 3080.5ms\n",
            "Speed: 2.9ms preprocess, 3080.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 3 handbags, 2476.3ms\n",
            "Speed: 3.0ms preprocess, 2476.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 3 handbags, 2306.3ms\n",
            "Speed: 3.2ms preprocess, 2306.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 5 handbags, 2286.3ms\n",
            "Speed: 2.9ms preprocess, 2286.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 3 handbags, 2324.3ms\n",
            "Speed: 2.6ms preprocess, 2324.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 25 persons, 3 handbags, 3201.4ms\n",
            "Speed: 3.0ms preprocess, 3201.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 3 handbags, 2353.6ms\n",
            "Speed: 3.5ms preprocess, 2353.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 5 handbags, 2295.0ms\n",
            "Speed: 2.6ms preprocess, 2295.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 4 handbags, 2305.0ms\n",
            "Speed: 3.0ms preprocess, 2305.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 4 handbags, 2292.0ms\n",
            "Speed: 2.8ms preprocess, 2292.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 4 handbags, 3257.7ms\n",
            "Speed: 2.8ms preprocess, 3257.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 4 handbags, 2314.1ms\n",
            "Speed: 2.9ms preprocess, 2314.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 3 handbags, 2289.8ms\n",
            "Speed: 3.8ms preprocess, 2289.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 3 handbags, 2284.4ms\n",
            "Speed: 2.9ms preprocess, 2284.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 3 handbags, 2277.3ms\n",
            "Speed: 2.9ms preprocess, 2277.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 3 handbags, 3266.3ms\n",
            "Speed: 2.9ms preprocess, 3266.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 3 handbags, 2286.5ms\n",
            "Speed: 3.1ms preprocess, 2286.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 4 handbags, 2305.0ms\n",
            "Speed: 2.9ms preprocess, 2305.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 3 handbags, 2282.2ms\n",
            "Speed: 2.9ms preprocess, 2282.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 handbags, 2286.1ms\n",
            "Speed: 3.1ms preprocess, 2286.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 handbags, 3267.6ms\n",
            "Speed: 3.8ms preprocess, 3267.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 backpack, 3 handbags, 2301.4ms\n",
            "Speed: 2.9ms preprocess, 2301.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 backpack, 3 handbags, 2281.6ms\n",
            "Speed: 2.9ms preprocess, 2281.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 backpacks, 3 handbags, 2307.3ms\n",
            "Speed: 2.9ms preprocess, 2307.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 backpack, 3 handbags, 2289.5ms\n",
            "Speed: 2.9ms preprocess, 2289.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 23 persons, 1 backpack, 3 handbags, 3305.4ms\n",
            "Speed: 2.9ms preprocess, 3305.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 backpack, 3 handbags, 2269.9ms\n",
            "Speed: 3.0ms preprocess, 2269.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 backpack, 3 handbags, 2277.2ms\n",
            "Speed: 2.9ms preprocess, 2277.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 backpack, 3 handbags, 2274.6ms\n",
            "Speed: 2.8ms preprocess, 2274.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 backpack, 3 handbags, 2305.2ms\n",
            "Speed: 2.9ms preprocess, 2305.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 backpack, 3 handbags, 3155.3ms\n",
            "Speed: 2.9ms preprocess, 3155.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 backpack, 4 handbags, 2272.5ms\n",
            "Speed: 2.9ms preprocess, 2272.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 backpack, 4 handbags, 2268.0ms\n",
            "Speed: 2.6ms preprocess, 2268.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 backpack, 4 handbags, 2273.3ms\n",
            "Speed: 4.7ms preprocess, 2273.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 backpack, 4 handbags, 2299.6ms\n",
            "Speed: 2.9ms preprocess, 2299.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 backpack, 4 handbags, 3166.6ms\n",
            "Speed: 2.9ms preprocess, 3166.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 backpack, 4 handbags, 2281.5ms\n",
            "Speed: 3.0ms preprocess, 2281.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 2 backpacks, 4 handbags, 2278.6ms\n",
            "Speed: 3.2ms preprocess, 2278.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 backpack, 4 handbags, 2283.5ms\n",
            "Speed: 3.0ms preprocess, 2283.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 car, 2 backpacks, 4 handbags, 2276.5ms\n",
            "Speed: 2.9ms preprocess, 2276.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 backpack, 3 handbags, 3146.1ms\n",
            "Speed: 2.9ms preprocess, 3146.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 car, 1 backpack, 5 handbags, 2293.5ms\n",
            "Speed: 2.9ms preprocess, 2293.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 backpack, 4 handbags, 2286.4ms\n",
            "Speed: 3.0ms preprocess, 2286.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 4 handbags, 2303.6ms\n",
            "Speed: 2.9ms preprocess, 2303.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 backpack, 4 handbags, 2427.5ms\n",
            "Speed: 2.9ms preprocess, 2427.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 2 backpacks, 5 handbags, 2998.6ms\n",
            "Speed: 3.0ms preprocess, 2998.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 backpack, 4 handbags, 2339.2ms\n",
            "Speed: 3.0ms preprocess, 2339.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 car, 1 backpack, 4 handbags, 2338.1ms\n",
            "Speed: 3.1ms preprocess, 2338.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 backpack, 4 handbags, 2315.0ms\n",
            "Speed: 3.0ms preprocess, 2315.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 backpack, 1 handbag, 2714.6ms\n",
            "Speed: 2.9ms preprocess, 2714.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 backpack, 2 handbags, 2754.0ms\n",
            "Speed: 5.6ms preprocess, 2754.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 backpack, 3 handbags, 2317.9ms\n",
            "Speed: 2.9ms preprocess, 2317.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 16 persons, 1 backpack, 2 handbags, 2337.3ms\n",
            "Speed: 3.0ms preprocess, 2337.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 3 handbags, 2326.9ms\n",
            "Speed: 3.1ms preprocess, 2326.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 backpack, 2 handbags, 2977.4ms\n",
            "Speed: 2.9ms preprocess, 2977.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 17 persons, 1 backpack, 2 handbags, 2488.0ms\n",
            "Speed: 3.6ms preprocess, 2488.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 handbag, 2322.8ms\n",
            "Speed: 3.3ms preprocess, 2322.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 3 handbags, 2315.8ms\n",
            "Speed: 2.6ms preprocess, 2315.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 handbag, 2336.2ms\n",
            "Speed: 2.9ms preprocess, 2336.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 handbag, 3221.7ms\n",
            "Speed: 3.1ms preprocess, 3221.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 handbag, 2324.6ms\n",
            "Speed: 3.1ms preprocess, 2324.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 handbag, 2306.5ms\n",
            "Speed: 2.9ms preprocess, 2306.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 handbag, 2306.2ms\n",
            "Speed: 4.0ms preprocess, 2306.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 handbag, 2319.7ms\n",
            "Speed: 2.9ms preprocess, 2319.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 handbag, 3209.5ms\n",
            "Speed: 2.9ms preprocess, 3209.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 21 persons, 1 handbag, 2318.0ms\n",
            "Speed: 3.1ms preprocess, 2318.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 handbag, 2315.1ms\n",
            "Speed: 3.0ms preprocess, 2315.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 handbag, 2331.0ms\n",
            "Speed: 3.0ms preprocess, 2331.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 handbag, 2305.6ms\n",
            "Speed: 3.0ms preprocess, 2305.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 1 handbag, 3154.6ms\n",
            "Speed: 3.1ms preprocess, 3154.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 24 persons, 2 handbags, 2326.5ms\n",
            "Speed: 4.0ms preprocess, 2326.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 22 persons, 2 handbags, 2312.9ms\n",
            "Speed: 2.9ms preprocess, 2312.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 2 handbags, 2280.8ms\n",
            "Speed: 3.5ms preprocess, 2280.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 20 persons, 1 handbag, 2367.3ms\n",
            "Speed: 2.9ms preprocess, 2367.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 2 handbags, 3013.3ms\n",
            "Speed: 3.0ms preprocess, 3013.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 19 persons, 1 handbag, 2274.5ms\n",
            "Speed: 2.8ms preprocess, 2274.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 18 persons, 1 handbag, 2277.2ms\n",
            "Speed: 2.8ms preprocess, 2277.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Video with tracking saved to: /content/output_tracked_v8.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cython\n",
        "!git clone https://github.com/gatagat/lap.git\n",
        "%cd lap\n",
        "!python setup.py install\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTCiLMAWErNy",
        "outputId": "7fc6969b-9194-4271-e5e3-8a6f5c9ced1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (3.0.12)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCloning into 'lap'...\n",
            "remote: Enumerating objects: 958, done.\u001b[K\n",
            "remote: Counting objects: 100% (410/410), done.\u001b[K\n",
            "remote: Compressing objects: 100% (189/189), done.\u001b[K\n",
            "remote: Total 958 (delta 276), reused 265 (delta 196), pack-reused 548 (from 1)\u001b[K\n",
            "Receiving objects: 100% (958/958), 1.69 MiB | 6.06 MiB/s, done.\n",
            "Resolving deltas: 100% (575/575), done.\n",
            "/content/lap\n",
            "running install\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating lap.egg-info\n",
            "writing lap.egg-info/PKG-INFO\n",
            "writing dependency_links to lap.egg-info/dependency_links.txt\n",
            "writing requirements to lap.egg-info/requires.txt\n",
            "writing top-level names to lap.egg-info/top_level.txt\n",
            "writing manifest file 'lap.egg-info/SOURCES.txt'\n",
            "reading manifest file 'lap.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "warning: no files found matching '*.txt'\n",
            "warning: no previously-included files matching '*/__pycache__' found anywhere in distribution\n",
            "warning: no previously-included files matching '*.pyc' found anywhere in distribution\n",
            "no previously-included directories found matching '.github'\n",
            "no previously-included directories found matching 'benchmark'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'lap.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build/lib.linux-x86_64-cpython-311/lap\n",
            "copying lap/lapmod.py -> build/lib.linux-x86_64-cpython-311/lap\n",
            "copying lap/__init__.py -> build/lib.linux-x86_64-cpython-311/lap\n",
            "creating build/lib.linux-x86_64-cpython-311/lap/tests\n",
            "copying lap/tests/test_simple.py -> build/lib.linux-x86_64-cpython-311/lap/tests\n",
            "copying lap/tests/test_utils.py -> build/lib.linux-x86_64-cpython-311/lap/tests\n",
            "copying lap/tests/test_lapjv.py -> build/lib.linux-x86_64-cpython-311/lap/tests\n",
            "copying lap/tests/test_arr_loop.py -> build/lib.linux-x86_64-cpython-311/lap/tests\n",
            "copying lap/tests/test_lapmod.py -> build/lib.linux-x86_64-cpython-311/lap/tests\n",
            "copying lap/tests/__init__.py -> build/lib.linux-x86_64-cpython-311/lap/tests\n",
            "copying lap/lapmod.py -> build/lib.linux-x86_64-cpython-311/lap\n",
            "copying lap/__init__.py -> build/lib.linux-x86_64-cpython-311/lap\n",
            "copying lap/tests/cost_eps.csv.gz -> build/lib.linux-x86_64-cpython-311/lap/tests\n",
            "copying lap/tests/test_simple.py -> build/lib.linux-x86_64-cpython-311/lap/tests\n",
            "copying lap/tests/test_utils.py -> build/lib.linux-x86_64-cpython-311/lap/tests\n",
            "copying lap/tests/test_lapjv.py -> build/lib.linux-x86_64-cpython-311/lap/tests\n",
            "copying lap/tests/test_arr_loop.py -> build/lib.linux-x86_64-cpython-311/lap/tests\n",
            "copying lap/tests/test_lapmod.py -> build/lib.linux-x86_64-cpython-311/lap/tests\n",
            "copying lap/tests/__init__.py -> build/lib.linux-x86_64-cpython-311/lap/tests\n",
            "running build_ext\n",
            "building 'lap._lapjv' extension\n",
            "creating build/temp.linux-x86_64-cpython-311/_lapjv_cpp\n",
            "x86_64-linux-gnu-g++ -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/numpy/core/include -I_lapjv_cpp -Ilap -I/usr/include/python3.11 -c _lapjv_cpp/_lapjv.cpp -o build/temp.linux-x86_64-cpython-311/_lapjv_cpp/_lapjv.o\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.11/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1929\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.11/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.11/dist-packages/numpy/core/include/numpy/arrayobject.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K_lapjv_cpp/_lapjv.cpp:1239\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.11/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wcpp\u0007-Wcpp\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K_lapjv_cpp/_lapjv.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KPyObject* __pyx_pf_6_lapjv_lapjv(PyObject*, PyArrayObject*, char, double, char)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K_lapjv_cpp/_lapjv.cpp:5422:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’ and ‘\u001b[01m\u001b[Kuint_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Kunsigned int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            " 5422 |   for (__pyx_t_1 = 0; \u001b[01;35m\u001b[K__pyx_t_1 < __pyx_t_14\u001b[m\u001b[K; __pyx_t_1+=1) {\n",
            "      |                       \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-g++ -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/numpy/core/include -I_lapjv_cpp -Ilap -I/usr/include/python3.11 -c _lapjv_cpp/lapjv.cpp -o build/temp.linux-x86_64-cpython-311/_lapjv_cpp/lapjv.o\n",
            "x86_64-linux-gnu-g++ -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/numpy/core/include -I_lapjv_cpp -Ilap -I/usr/include/python3.11 -c _lapjv_cpp/lapmod.cpp -o build/temp.linux-x86_64-cpython-311/_lapjv_cpp/lapmod.o\n",
            "x86_64-linux-gnu-g++ -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -shared -Wl,-O1 -Wl,-Bsymbolic-functions build/temp.linux-x86_64-cpython-311/_lapjv_cpp/_lapjv.o build/temp.linux-x86_64-cpython-311/_lapjv_cpp/lapjv.o build/temp.linux-x86_64-cpython-311/_lapjv_cpp/lapmod.o -L/usr/lib/x86_64-linux-gnu -o build/lib.linux-x86_64-cpython-311/lap/_lapjv.cpython-311-x86_64-linux-gnu.so\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/lap\n",
            "copying build/lib.linux-x86_64-cpython-311/lap/lapmod.py -> build/bdist.linux-x86_64/egg/lap\n",
            "copying build/lib.linux-x86_64-cpython-311/lap/_lapjv.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/lap\n",
            "creating build/bdist.linux-x86_64/egg/lap/tests\n",
            "copying build/lib.linux-x86_64-cpython-311/lap/tests/cost_eps.csv.gz -> build/bdist.linux-x86_64/egg/lap/tests\n",
            "copying build/lib.linux-x86_64-cpython-311/lap/tests/test_simple.py -> build/bdist.linux-x86_64/egg/lap/tests\n",
            "copying build/lib.linux-x86_64-cpython-311/lap/tests/test_utils.py -> build/bdist.linux-x86_64/egg/lap/tests\n",
            "copying build/lib.linux-x86_64-cpython-311/lap/tests/test_lapjv.py -> build/bdist.linux-x86_64/egg/lap/tests\n",
            "copying build/lib.linux-x86_64-cpython-311/lap/tests/test_arr_loop.py -> build/bdist.linux-x86_64/egg/lap/tests\n",
            "copying build/lib.linux-x86_64-cpython-311/lap/tests/test_lapmod.py -> build/bdist.linux-x86_64/egg/lap/tests\n",
            "copying build/lib.linux-x86_64-cpython-311/lap/tests/__init__.py -> build/bdist.linux-x86_64/egg/lap/tests\n",
            "copying build/lib.linux-x86_64-cpython-311/lap/__init__.py -> build/bdist.linux-x86_64/egg/lap\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lap/lapmod.py to lapmod.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lap/tests/test_simple.py to test_simple.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lap/tests/test_utils.py to test_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lap/tests/test_lapjv.py to test_lapjv.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lap/tests/test_arr_loop.py to test_arr_loop.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lap/tests/test_lapmod.py to test_lapmod.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lap/tests/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lap/__init__.py to __init__.cpython-311.pyc\n",
            "creating stub loader for lap/_lapjv.cpython-311-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lap/_lapjv.py to _lapjv.cpython-311.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying lap.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying lap.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying lap.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying lap.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying lap.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "lap.__pycache__._lapjv.cpython-311: module references __file__\n",
            "lap.tests.__pycache__.test_utils.cpython-311: module references __file__\n",
            "creating dist\n",
            "creating 'dist/lap-0.5.12-py3.11-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing lap-0.5.12-py3.11-linux-x86_64.egg\n",
            "creating /usr/local/lib/python3.11/dist-packages/lap-0.5.12-py3.11-linux-x86_64.egg\n",
            "Extracting lap-0.5.12-py3.11-linux-x86_64.egg to /usr/local/lib/python3.11/dist-packages\n",
            "Adding lap 0.5.12 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.11/dist-packages/lap-0.5.12-py3.11-linux-x86_64.egg\n",
            "Processing dependencies for lap==0.5.12\n",
            "Searching for numpy==1.26.4\n",
            "Best match: numpy 1.26.4\n",
            "Adding numpy 1.26.4 to easy-install.pth file\n",
            "detected new path './lap-0.5.12-py3.11-linux-x86_64.egg'\n",
            "Installing f2py script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Finished processing dependencies for lap==0.5.12\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch torchvision torchaudio -y\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Bb3RnTY2Exh5",
        "outputId": "f1d8abc2-86e1-41bc-dde9-f9d5e6b3b71d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: torch 2.5.1+cu124\n",
            "Uninstalling torch-2.5.1+cu124:\n",
            "  Successfully uninstalled torch-2.5.1+cu124\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: torchvision 0.20.1+cu124\n",
            "Uninstalling torchvision-0.20.1+cu124:\n",
            "  Successfully uninstalled torchvision-0.20.1+cu124\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: torchaudio 2.5.1+cu124\n",
            "Uninstalling torchaudio-2.5.1+cu124:\n",
            "  Successfully uninstalled torchaudio-2.5.1+cu124\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.11/dist-packages/lap-0.5.12-py3.11-linux-x86_64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp311-cp311-linux_x86_64.whl (780.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.5/780.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp311-cp311-linux_x86_64.whl (7.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m797.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: nvidia-nvtx-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n",
            "    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.5.147\n",
            "    Uninstalling nvidia-curand-cu12-10.3.5.147:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n",
            "    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cufft-cu12 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nvtx-cu12-12.1.105 torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen",
                  "torchvision"
                ]
              },
              "id": "0ea617b53bf0446da2013e39956cc3e5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bytetracker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqxW9aaJFwqY",
        "outputId": "0645d274-fd21-425a-9b32-874ef59744bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.11/dist-packages/lap-0.5.12-py3.11-linux-x86_64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting bytetracker\n",
            "  Using cached bytetracker-0.3.2-py3-none-any.whl\n",
            "Collecting lap==0.4.0 (from bytetracker)\n",
            "  Using cached lap-0.4.0.tar.gz (1.5 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scipy==1.9.3 (from bytetracker)\n",
            "  Using cached scipy-1.9.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "Collecting torch==1.13.0 (from bytetracker)\n",
            "  Using cached torch-1.13.0-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Collecting numpy<1.26.0,>=1.18.5 (from scipy==1.9.3->bytetracker)\n",
            "  Using cached numpy-1.25.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==1.13.0->bytetracker) (4.12.2)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==1.13.0->bytetracker)\n",
            "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==1.13.0->bytetracker)\n",
            "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==1.13.0->bytetracker)\n",
            "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==1.13.0->bytetracker)\n",
            "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->bytetracker) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->bytetracker) (0.45.1)\n",
            "Using cached scipy-1.9.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.4 MB)\n",
            "Using cached torch-1.13.0-cp311-cp311-manylinux1_x86_64.whl (890.2 MB)\n",
            "Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "Using cached numpy-1.25.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "Building wheels for collected packages: lap\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for lap (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for lap\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for lap\n",
            "Failed to build lap\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (lap)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cython\n",
        "!git clone https://github.com/gatagat/lap.git\n",
        "%cd lap\n",
        "!python setup.py install\n",
        "%cd ..\n",
        "\n",
        "# Verify lap installation\n",
        "try:\n",
        "    import lap\n",
        "    print(\"lap installed successfully!\")\n",
        "except ImportError:\n",
        "    print(\"lap installation failed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7apNX4FGOjV",
        "outputId": "d5732fe9-b5d6-412f-ba43-1f5d2a9ad65e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.11/dist-packages/lap-0.5.12-py3.11-linux-x86_64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (3.0.12)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mfatal: destination path 'lap' already exists and is not an empty directory.\n",
            "/content/lap\n",
            "running install\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing lap.egg-info/PKG-INFO\n",
            "writing dependency_links to lap.egg-info/dependency_links.txt\n",
            "writing requirements to lap.egg-info/requires.txt\n",
            "writing top-level names to lap.egg-info/top_level.txt\n",
            "reading manifest file 'lap.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "warning: no files found matching '*.txt'\n",
            "warning: no previously-included files matching '*/__pycache__' found anywhere in distribution\n",
            "warning: no previously-included files matching '*.pyc' found anywhere in distribution\n",
            "no previously-included directories found matching '.github'\n",
            "no previously-included directories found matching 'benchmark'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'lap.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "copying lap/lapmod.py -> build/lib.linux-x86_64-cpython-311/lap\n",
            "copying lap/__init__.py -> build/lib.linux-x86_64-cpython-311/lap\n",
            "copying lap/tests/test_simple.py -> build/lib.linux-x86_64-cpython-311/lap/tests\n",
            "copying lap/tests/test_utils.py -> build/lib.linux-x86_64-cpython-311/lap/tests\n",
            "copying lap/tests/test_lapjv.py -> build/lib.linux-x86_64-cpython-311/lap/tests\n",
            "copying lap/tests/test_arr_loop.py -> build/lib.linux-x86_64-cpython-311/lap/tests\n",
            "copying lap/tests/test_lapmod.py -> build/lib.linux-x86_64-cpython-311/lap/tests\n",
            "copying lap/tests/__init__.py -> build/lib.linux-x86_64-cpython-311/lap/tests\n",
            "copying lap/lapmod.py -> build/lib.linux-x86_64-cpython-311/lap\n",
            "copying lap/__init__.py -> build/lib.linux-x86_64-cpython-311/lap\n",
            "copying lap/tests/cost_eps.csv.gz -> build/lib.linux-x86_64-cpython-311/lap/tests\n",
            "copying lap/tests/test_simple.py -> build/lib.linux-x86_64-cpython-311/lap/tests\n",
            "copying lap/tests/test_utils.py -> build/lib.linux-x86_64-cpython-311/lap/tests\n",
            "copying lap/tests/test_lapjv.py -> build/lib.linux-x86_64-cpython-311/lap/tests\n",
            "copying lap/tests/test_arr_loop.py -> build/lib.linux-x86_64-cpython-311/lap/tests\n",
            "copying lap/tests/test_lapmod.py -> build/lib.linux-x86_64-cpython-311/lap/tests\n",
            "copying lap/tests/__init__.py -> build/lib.linux-x86_64-cpython-311/lap/tests\n",
            "running build_ext\n",
            "building 'lap._lapjv' extension\n",
            "x86_64-linux-gnu-g++ -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/numpy/core/include -I_lapjv_cpp -Ilap -I/usr/include/python3.11 -c _lapjv_cpp/_lapjv.cpp -o build/temp.linux-x86_64-cpython-311/_lapjv_cpp/_lapjv.o\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.11/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1929\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.11/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.11/dist-packages/numpy/core/include/numpy/arrayobject.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K_lapjv_cpp/_lapjv.cpp:1239\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.11/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wcpp\u0007-Wcpp\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K_lapjv_cpp/_lapjv.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KPyObject* __pyx_pf_6_lapjv_lapjv(PyObject*, PyArrayObject*, char, double, char)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K_lapjv_cpp/_lapjv.cpp:5422:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’ and ‘\u001b[01m\u001b[Kuint_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Kunsigned int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            " 5422 |   for (__pyx_t_1 = 0; \u001b[01;35m\u001b[K__pyx_t_1 < __pyx_t_14\u001b[m\u001b[K; __pyx_t_1+=1) {\n",
            "      |                       \u001b[01;35m\u001b[K~~~~~~~~~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-g++ -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/numpy/core/include -I_lapjv_cpp -Ilap -I/usr/include/python3.11 -c _lapjv_cpp/lapjv.cpp -o build/temp.linux-x86_64-cpython-311/_lapjv_cpp/lapjv.o\n",
            "x86_64-linux-gnu-g++ -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/numpy/core/include -I_lapjv_cpp -Ilap -I/usr/include/python3.11 -c _lapjv_cpp/lapmod.cpp -o build/temp.linux-x86_64-cpython-311/_lapjv_cpp/lapmod.o\n",
            "x86_64-linux-gnu-g++ -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -shared -Wl,-O1 -Wl,-Bsymbolic-functions build/temp.linux-x86_64-cpython-311/_lapjv_cpp/_lapjv.o build/temp.linux-x86_64-cpython-311/_lapjv_cpp/lapjv.o build/temp.linux-x86_64-cpython-311/_lapjv_cpp/lapmod.o -L/usr/lib/x86_64-linux-gnu -o build/lib.linux-x86_64-cpython-311/lap/_lapjv.cpython-311-x86_64-linux-gnu.so\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/lap\n",
            "copying build/lib.linux-x86_64-cpython-311/lap/lapmod.py -> build/bdist.linux-x86_64/egg/lap\n",
            "copying build/lib.linux-x86_64-cpython-311/lap/_lapjv.cpython-311-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/lap\n",
            "creating build/bdist.linux-x86_64/egg/lap/tests\n",
            "copying build/lib.linux-x86_64-cpython-311/lap/tests/cost_eps.csv.gz -> build/bdist.linux-x86_64/egg/lap/tests\n",
            "copying build/lib.linux-x86_64-cpython-311/lap/tests/test_simple.py -> build/bdist.linux-x86_64/egg/lap/tests\n",
            "copying build/lib.linux-x86_64-cpython-311/lap/tests/test_utils.py -> build/bdist.linux-x86_64/egg/lap/tests\n",
            "copying build/lib.linux-x86_64-cpython-311/lap/tests/test_lapjv.py -> build/bdist.linux-x86_64/egg/lap/tests\n",
            "copying build/lib.linux-x86_64-cpython-311/lap/tests/test_arr_loop.py -> build/bdist.linux-x86_64/egg/lap/tests\n",
            "copying build/lib.linux-x86_64-cpython-311/lap/tests/test_lapmod.py -> build/bdist.linux-x86_64/egg/lap/tests\n",
            "copying build/lib.linux-x86_64-cpython-311/lap/tests/__init__.py -> build/bdist.linux-x86_64/egg/lap/tests\n",
            "copying build/lib.linux-x86_64-cpython-311/lap/__init__.py -> build/bdist.linux-x86_64/egg/lap\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lap/lapmod.py to lapmod.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lap/tests/test_simple.py to test_simple.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lap/tests/test_utils.py to test_utils.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lap/tests/test_lapjv.py to test_lapjv.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lap/tests/test_arr_loop.py to test_arr_loop.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lap/tests/test_lapmod.py to test_lapmod.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lap/tests/__init__.py to __init__.cpython-311.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lap/__init__.py to __init__.cpython-311.pyc\n",
            "creating stub loader for lap/_lapjv.cpython-311-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/lap/_lapjv.py to _lapjv.cpython-311.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying lap.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying lap.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying lap.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying lap.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying lap.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "lap.__pycache__._lapjv.cpython-311: module references __file__\n",
            "lap.tests.__pycache__.test_utils.cpython-311: module references __file__\n",
            "creating 'dist/lap-0.5.12-py3.11-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing lap-0.5.12-py3.11-linux-x86_64.egg\n",
            "removing '/usr/local/lib/python3.11/dist-packages/lap-0.5.12-py3.11-linux-x86_64.egg' (and everything under it)\n",
            "creating /usr/local/lib/python3.11/dist-packages/lap-0.5.12-py3.11-linux-x86_64.egg\n",
            "Extracting lap-0.5.12-py3.11-linux-x86_64.egg to /usr/local/lib/python3.11/dist-packages\n",
            "Adding lap 0.5.12 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.11/dist-packages/lap-0.5.12-py3.11-linux-x86_64.egg\n",
            "Processing dependencies for lap==0.5.12\n",
            "Searching for numpy==1.26.4\n",
            "Best match: numpy 1.26.4\n",
            "Adding numpy 1.26.4 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.11/dist-packages\n",
            "Finished processing dependencies for lap==0.5.12\n",
            "/content\n",
            "lap installed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch torchvision torchaudio -y\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QMAscPb5GnSR",
        "outputId": "b6556a9f-c532-41b5-f1a1-d6eddb265655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: torch 2.5.1+cu121\n",
            "Uninstalling torch-2.5.1+cu121:\n",
            "  Successfully uninstalled torch-2.5.1+cu121\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: torchvision 0.20.1+cu121\n",
            "Uninstalling torchvision-0.20.1+cu121:\n",
            "  Successfully uninstalled torchvision-0.20.1+cu121\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: torchaudio 2.5.1+cu121\n",
            "Uninstalling torchaudio-2.5.1+cu121:\n",
            "  Successfully uninstalled torchaudio-2.5.1+cu121\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.11/dist-packages/lap-0.5.12-py3.11-linux-x86_64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch\n",
            "  Using cached https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp311-cp311-linux_x86_64.whl (780.5 MB)\n",
            "Collecting torchvision\n",
            "  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp311-cp311-linux_x86_64.whl (7.3 MB)\n",
            "Collecting torchaudio\n",
            "  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: nvidia-cufft-cu12, torch, torchvision, torchaudio\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cufft-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed nvidia-cufft-cu12 torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen"
                ]
              },
              "id": "415911aefe2345e1a5129762b17b512c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "from bytetracker import BYTETracker\n",
        "import numpy as np\n",
        "\n",
        "# Download and prepare dataset (example: CrowdHuman)\n",
        "!pip install roboflow\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"YOUR_ROBOFLOW_API_KEY\") #replace with your roboflow api key\n",
        "project = rf.workspace(\"roboflow-100\").project(\"crowdhuman-yolov8\")\n",
        "dataset = project.version(1).download(\"yolov8\")\n",
        "\n",
        "# Train YOLOv8 model\n",
        "model = YOLO(\"yolov8n.pt\")  # Use a smaller base model for faster training\n",
        "results = model.train(data=dataset.location + \"/data.yaml\", epochs=50, imgsz=640)\n",
        "\n",
        "# Evaluate model and print accuracy\n",
        "metrics = model.val()\n",
        "accuracy = metrics.box.map50\n",
        "print(f\"Model Accuracy (mAP50): {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Load trained model\n",
        "model = YOLO(\"runs/detect/train/weights/best.pt\")\n",
        "\n",
        "# Load video\n",
        "video_path = '/content/production_id_4196258 (720p).mp4'  #@param {type:\"string\"}\n",
        "output_path = '/content/output_tracked_bytetrack.mp4'\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "if not cap.isOpened():\n",
        "    print(f\"Error opening video file: {video_path}\")\n",
        "    exit()\n",
        "\n",
        "# Video writer\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# Initialize ByteTrack\n",
        "tracker = BYTETracker(track_thresh=0.25, track_buffer=30, match_thresh=0.8)\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Object detection\n",
        "    results = model(frame, stream=True)\n",
        "    detections = []\n",
        "    for r in results:\n",
        "        for box in r.boxes:\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            conf = box.conf[0].item()\n",
        "            cls = int(box.cls[0].item())\n",
        "            if cls == 0:  # Person class\n",
        "                detections.append([x1, y1, x2, y2, conf])\n",
        "\n",
        "    # ByteTrack tracking\n",
        "    track_results = tracker.update(np.array(detections), frame)\n",
        "\n",
        "    # Draw bounding boxes and IDs\n",
        "    for track in track_results:\n",
        "        track_id = int(track[4])\n",
        "        x1, y1, x2, y2 = map(int, track[:4])\n",
        "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "        cv2.putText(frame, str(track_id), (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "\n",
        "    # Display crowd count\n",
        "    cv2.putText(frame, f\"People Count: {len(track_results)}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "\n",
        "    out.write(frame)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "print(f\"Video with tracking saved to: {output_path}\")"
      ],
      "metadata": {
        "id": "gDv0MbzoHoMO",
        "outputId": "4eb0ae9e-c262-4e20-aab2-984aa6bab320",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'bytetracker'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-952d38ba2a8a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbytetracker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBYTETracker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bytetracker'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}