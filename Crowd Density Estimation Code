import cv2
import numpy as np
import torch
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import time
import seaborn as sns
import pandas as pd
from torchvision import models
from IPython.display import clear_output
from scipy.ndimage import gaussian_filter
from sklearn.metrics import confusion_matrix
from google.colab.patches import cv2_imshow
from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive')

# Device setup
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Define CSRNet Model
class CSRNet(torch.nn.Module):
    def __init__(self):
        super(CSRNet, self).__init__()
        self.frontend = models.vgg16_bn(weights=models.VGG16_BN_Weights.DEFAULT).features[:30]  # Extract first 30 layers
        self.density_map = torch.nn.Conv2d(512, 1, kernel_size=1)  # 1-channel density map

    def forward(self, x):
        x = self.frontend(x)
        x = self.density_map(x)
        return x

# Instantiate Model
model = CSRNet().to(device)
model.eval()  # Set model to evaluation mode

# Preprocessing Function
def preprocess_frame(frame):
    transform = transforms.Compose([
        transforms.ToPILImage(),
        transforms.Resize((224, 224)),  # Resize for model compatibility
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    return transform(frame).unsqueeze(0)

# Load video
video_path = "/content/drive/MyDrive/vecteezy_a-crowd-walking-on-the-street-in-slow-motion_13996591.mp4"
cap = cv2.VideoCapture(video_path)

if not cap.isOpened():
    print(f"Error: Could not open video file at {video_path}")
    exit()

# Get video properties
original_fps = cap.get(cv2.CAP_PROP_FPS)
frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

new_fps = max(1, original_fps // 10)  # Reduce FPS to 1/10th, but ensure it's at least 1 FPS
frame_skip = max(1, int(original_fps / new_fps))  # Process every 10th frame

frame_count = 0
crowd_counts = []
frame_times = []
start_time = time.time()

while cap.isOpened():
    ret, frame = cap.read()

    if not ret:
        break  # Exit if video ends or frame is unreadable

    frame_count += 1

    # Process only 1 out of every `frame_skip` frames
    if frame_count % frame_skip != 0:
        continue  

    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert to RGB
    input_tensor = preprocess_frame(frame_rgb).to(device)

    with torch.no_grad():
        density_map = model(input_tensor)
        crowd_count = density_map.sum().item()

    crowd_counts.append(crowd_count)  # Store count for graph
    frame_times.append(time.time() - start_time)

    print(f"Frame {frame_count} - Estimated Crowd Count: {crowd_count:.2f}")

    time.sleep(0.00001)  # Small delay for display
    clear_output(wait=True)  # Clear output for smooth display

cap.release()
print("Video processing completed.")

# Convert data into DataFrame
df = pd.DataFrame({'Time (s)': frame_times, 'Crowd Density': crowd_counts})

# Smooth the density values using Gaussian filter
df['Smoothed Density'] = gaussian_filter(df['Crowd Density'], sigma=1.5)

# Create heatmap
plt.figure(figsize=(12, 4))
sns.heatmap(
    df.set_index('Time (s)').T, 
    cmap='jet', 
    annot=False, 
    cbar=True, 
    linewidths=0.5
)
plt.title('Frame-wise Crowd Density Heatmap')
plt.xlabel('Time (seconds)')
plt.ylabel('Density')
heatmap_path = "/content/drive/MyDrive/crowd_density_heatmap.png"
plt.savefig(heatmap_path)
plt.show()

print(f"Heatmap saved at: {heatmap_path}")

# Generate Graph: Crowd Density Over Time
plt.figure(figsize=(10, 5))
plt.plot(df['Time (s)'], df['Crowd Density'], marker='o', linestyle='-', color='b', label="Estimated Crowd")
plt.xlabel("Time (seconds)")
plt.ylabel("Crowd Count")
plt.title("Crowd Density Over Time")
plt.legend()
plt.grid(True)
graph_path = "/content/drive/MyDrive/crowd_density_graph.png"
plt.savefig(graph_path)
plt.show()

print(f"Graph saved at: {graph_path}")
